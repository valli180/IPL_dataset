{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c288e0-62b9-44c1-86bb-3fe206462c62",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 123)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, test_size = 0.2, random_state = 123)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b854e-33e5-4462-9ca2-2a81f0b2f1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "844b1cf2-ed6f-4212-bcaf-8db2a7ec6de4",
   "metadata": {},
   "source": [
    "#### Make pipeline\n",
    "\n",
    "pipe = make_pipeline(DummyClassifier(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5dfcf-1602-4923-919b-edf93b80bbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82df0e22-62bc-4e10-9f05-8fb5fa5f0b1c",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "result = pd.DataFrame(cross_validate(pipe, X_train, y_train, cv= 10,return_train_score = True, scoring = \"f1\")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4047b9-af58-4717-b01b-46edf0187372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0e2bdcf-a72a-4669-9439-2a59d2db360a",
   "metadata": {},
   "source": [
    "### Make Column Tranformer\n",
    "<u>from sklearn.compose import ColumnTransformer, make_column_transformer\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abc9b893-0fdd-4924-b1e4-ea3ed60679e1",
   "metadata": {},
   "source": [
    "\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "ordinal_transformer_reg = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OrdinalEncoder(categories=ordering_ordinal_reg),\n",
    ")\n",
    "\n",
    "ordinal_transformer_oth = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OrdinalEncoder(categories=ordering_ordinal_oth),\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_features),\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer_reg, ordinal_features_reg),\n",
    "    (ordinal_transformer_oth, ordinal_features_oth),\n",
    "    (categorical_transformer, categorical_features),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7996d7-7df5-4386-80f2-46641baa4193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "193b6ec5-5cc3-44c6-889b-64c0a6d5387f",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "<u>from sklearn.metrics import ConfusionMatrixDisplay  \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6922644a-1f26-4a0f-86f8-7a2fe8cc0846",
   "metadata": {},
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "cm = ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe, X_valid, y_valid, values_format=\"d\", display_labels=[\"Non fraud\", \"fraud\"]   # Displayed as color plot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f4c0b-1dcc-4ac0-b078-a7fa62e89d9f",
   "metadata": {},
   "source": [
    "<u>from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a758884-e1c5-4d74-a780-280e77c0083f",
   "metadata": {},
   "source": [
    "predictions = pipe.predict(X_valid)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_valid, predictions).ravel()\n",
    "\n",
    "plot_confusion_matrix_example(TN, FP, FN, TP) #plot no colors, arranged column wise, first row filled,then second\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86c623-f2db-4fc2-960f-38ae024cd4b9",
   "metadata": {},
   "source": [
    "<u>from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f4b6fb9-a4a0-40b8-b879-0c0de714a1c6",
   "metadata": {},
   "source": [
    "confusion_matrix(y_train, cross_val_predict(pipe, X_train, y_train)) # in the form of an array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2754630-0403-4df8-a8ec-798baed75dd4",
   "metadata": {},
   "source": [
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d8e0e3-c1be-432e-bd64-8490490f9357",
   "metadata": {},
   "source": [
    "Accuracy is a good measure for balanced data, but when there is class imbalance, accuracy is not the correct metrics to be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3cee65-0372-4bfd-92fc-f33d6212664c",
   "metadata": {},
   "source": [
    ".score will return accuracy. But in case of classification models, we need, precison, recall and f1 score.\n",
    "F1 score is generally used for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df114ac7-9b4c-4b64-b4a4-d8cf5277539a",
   "metadata": {},
   "source": [
    "pipe.classes_ # ? \n",
    "\n",
    "pipe_lr.named_steps[\"logisticregression\"].classes_# ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff18ea-9c75-44af-91ce-8f17c60e1dad",
   "metadata": {},
   "source": [
    "<u>from sklearn.metrics import classification_report\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_valid, pipe_lr.predict(X_valid), target_names=[\"non-fraud\", \"fraud\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48ea64-219c-47a6-9901-6f3dabcaac66",
   "metadata": {},
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "y_pred = pipe.predict_proba(X_test)[ : ,1] > 0.5\n",
    "\n",
    "y_pred = pipe.predict_proba(X_test)[:,1] > 0.1\n",
    "\n",
    "The above y_pred code means that even at the slightest probability of 0.1% predict y_pred to be in positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fbdabd-db91-4087-b262-d4cbb3a831f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f8d3df9-fa5a-4920-8b69-b9395a89419d",
   "metadata": {},
   "source": [
    "### ROC Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a4acd-8f67-4673-8d75-0804d7bf83dc",
   "metadata": {},
   "source": [
    "<u>from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "roc_plot= RocCurveDisplay.from_estimator(final_svc_model, X_test, y_test) #fit the model on train_df before this\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64589ba5-7405-40d5-b8f8-6b88e6349cb7",
   "metadata": {},
   "source": [
    "### PR Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ece952-e99b-4411-9c01-77a4cb4264dd",
   "metadata": {},
   "source": [
    "<u>from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "pr_curve = PrecisionRecallDisplay.from_estimator(final_svc_model, X_test, y_test) # fit the model on train_df before this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077f7fe-5c18-4fc8-82e5-97d01171f7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "579d46d1-b6b8-4fea-aa7a-2e1a61881cf0",
   "metadata": {},
   "source": [
    "Increasing the threshold means,higher bar for predicting the positive case.\n",
    "Increasing the precision, we dont want to have any false positives. Precision will increase , occasionally might decrease\n",
    "recall may stay the same or go down. \n",
    "\n",
    "Decreasing the threshold means we are risking to have false positive for having higher true positive.\n",
    "recall may remain same or might increase\n",
    "\n",
    "There is always trade off between precison and recall depending on the threshold.\n",
    "Lower thershold(left of pr or ap curve) will cause low precision, increasing the threshold(moving to right) increases precision but at the expense of lowering the recall. The extreme upper right of the curve represents the ideal situation where recall = precision = 1, where there are no false positives or false negatives, which is ideal case, not possible.\n",
    "\n",
    "Ap score is the summary across all the threshold- we can find the threshold at which we have a balance between the recall and the precision from the above pr curve.\n",
    "\n",
    "Ap score measures the quality of the predict_proba\n",
    "while f1 score measures the quality of the predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65305d77-820e-4dff-a219-3fe13a08594c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bcb6b5e-0932-45b5-9509-1951f89f64fe",
   "metadata": {},
   "source": [
    "<u>from sklearn.metrics import average_precision_score\n",
    "\n",
    "ap_lr = average_precision_score(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6402012-2af3-4b70-912c-e704c9f12b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
